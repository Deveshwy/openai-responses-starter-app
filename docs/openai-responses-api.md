# OpenAI Responses API Documentation

## Text Generation and Prompting

With the OpenAI API, you can use a large language model to generate text from a prompt. Models can generate almost any kind of text responseâ€”like code, mathematical equations, structured JSON data, or human-like prose.

### Basic Example

```javascript
import OpenAI from "openai";
const client = new OpenAI();

const response = await client.responses.create({
    model: "gpt-4.1",
    input: "Write a one-sentence bedtime story about a unicorn."
});

console.log(response.output_text);
```

### Response Structure

The response contains an `output` array with content generated by the model:

```json
[
    {
        "id": "msg_67b73f697ba4819183a15cc17d011509",
        "type": "message",
        "role": "assistant",
        "content": [
            {
                "type": "output_text",
                "text": "Under the soft glow of the moon, Luna the unicorn danced through fields of twinkling stardust, leaving trails of dreams for every child asleep.",
                "annotations": []
            }
        ]
    }
]
```

**Important:** The `output` array often has more than one item! It can contain tool calls, reasoning tokens, and other items. It is not safe to assume that the model's text output is at `output[0].content[0].text`.

## Model Selection

Key factors when choosing a model:

- **Reasoning models** - Generate internal chain of thought, excel at complex tasks and multi-step planning, slower and more expensive
- **GPT models** - Fast, cost-efficient, highly intelligent, benefit from explicit instructions
- **Large vs small models** - Trade-offs for speed, cost, and intelligence

Recommended: `gpt-4.1` offers solid combination of intelligence, speed, and cost effectiveness.

## Prompt Engineering

### Message Roles and Instructions

Use the `instructions` parameter or message roles with differing levels of authority:

```javascript
// Using instructions parameter
const response = await client.responses.create({
    model: "gpt-4.1",
    instructions: "Talk like a pirate.",
    input: "Are semicolons optional in JavaScript?",
});

// Using message roles
const response = await client.responses.create({
    model: "gpt-4.1",
    input: [
        {
            role: "developer",
            content: "Talk like a pirate."
        },
        {
            role: "user",
            content: "Are semicolons optional in JavaScript?",
        },
    ],
});
```

### Message Role Priority

| Role | Description |
|------|-------------|
| developer | Instructions from app developer, highest priority |
| user | Instructions from end user, prioritized behind developer |
| assistant | Messages generated by the model |

### Reusable Prompts

Create reusable prompts in the dashboard with placeholders:

```javascript
const response = await client.responses.create({
    model: "gpt-4.1",
    prompt: {
        id: "pmpt_abc123",
        version: "2",
        variables: {
            customer_name: "Jane Doe",
            product: "40oz juice box"
        }
    }
});
```

### Message Formatting

Use Markdown and XML tags to structure prompts:

```text
# Identity
You are a coding assistant...

# Instructions
* Use snake case for variables
* Use var keyword for declarations

# Examples
<user_query>
How do I declare a string variable?
</user_query>

<assistant_response>
var first_name = "Anna";
</assistant_response>
```

## GPT-4.1 Best Practices

### System Prompt Reminders

Include three key types of reminders:

```text
## PERSISTENCE
You are an agent - keep going until the query is completely resolved.

## TOOL CALLING
Use your tools to gather information; do NOT guess or make up answers.

## PLANNING
Plan extensively before each function call and reflect on outcomes.
```

### Tool Calls

Use the tools field exclusively in API requests for best performance.

### Long Context Usage

- GPT-4.1 has 1M token input context window
- Put critical instructions at both top and bottom of prompt
- Use XML delimiters for separating context

### Chain of Thought

Basic instruction:
```text
First, think carefully step by step about what documents are needed to answer the query.
```

### Instruction Following

Recommended workflow:
1. Start with high-level "Instructions" section
2. Add specific behavior sections as needed
3. Use ordered lists for step-by-step workflows
4. Check for conflicting instructions
5. Add examples demonstrating desired behavior

## Reasoning vs GPT Models

- **Reasoning models**: Like a senior co-worker - give goals, trust them with details
- **GPT models**: Like a junior co-worker - perform best with explicit instructions

## Key API Features

- Server-Sent Events (SSE) for streaming
- Supports parallel tool calls
- Different event types for different stages
- Tool outputs feed back into conversation